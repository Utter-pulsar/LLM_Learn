{"loss": 3.49956155, "acc": 0.4019517, "grad_norm": 6.4375, "learning_rate": 2e-05, "epoch": 1.0, "global_step": 1}
{"loss": 1.69518483, "acc": 0.20142452, "grad_norm": 4.1875, "learning_rate": 0.0001, "epoch": 3.0, "global_step": 5}
{"loss": 1.179321, "acc": 0.22218409, "grad_norm": 1.53125, "learning_rate": 9.474e-05, "epoch": 5.33333333, "global_step": 10}
{"loss": 0.8430027, "acc": 0.32917449, "grad_norm": 1.34375, "learning_rate": 8.947e-05, "epoch": 8.0, "global_step": 15}
{"loss": 0.57016377, "acc": 0.39561129, "grad_norm": 1.2578125, "learning_rate": 8.421e-05, "epoch": 10.66666667, "global_step": 20}
{"loss": 0.32824948, "acc": 0.36537356, "grad_norm": 0.36914062, "learning_rate": 7.895e-05, "epoch": 13.0, "global_step": 25}
{"loss": 0.27504699, "acc": 0.48988757, "grad_norm": 1.3984375, "learning_rate": 7.368e-05, "epoch": 16.0, "global_step": 30}
{"loss": 0.1609871, "acc": 0.51440158, "grad_norm": 1.109375, "learning_rate": 6.842e-05, "epoch": 19.0, "global_step": 35}
{"loss": 0.08093585, "acc": 0.41482348, "grad_norm": 0.546875, "learning_rate": 6.316e-05, "epoch": 21.33333333, "global_step": 40}
{"loss": 0.05608666, "acc": 0.4839025, "grad_norm": 0.59375, "learning_rate": 5.789e-05, "epoch": 24.0, "global_step": 45}
{"loss": 0.03458886, "acc": 0.49087057, "grad_norm": 0.6171875, "learning_rate": 5.263e-05, "epoch": 26.66666667, "global_step": 50}
{"eval_loss": 0.66162658, "eval_acc": 0.79069767, "eval_runtime": 7.885, "eval_samples_per_second": 0.127, "eval_steps_per_second": 0.127, "epoch": 26.66666667, "global_step": 50}
{"loss": 0.02210911, "acc": 0.4319459, "grad_norm": 0.4453125, "learning_rate": 4.737e-05, "epoch": 29.0, "global_step": 55}
{"loss": 0.01778363, "acc": 0.55861731, "grad_norm": 0.3046875, "learning_rate": 4.211e-05, "epoch": 32.0, "global_step": 60}
{"loss": 0.01234441, "acc": 0.56028085, "grad_norm": 0.3125, "learning_rate": 3.684e-05, "epoch": 35.0, "global_step": 65}
{"loss": 0.00722974, "acc": 0.4366137, "grad_norm": 0.21972656, "learning_rate": 3.158e-05, "epoch": 37.33333333, "global_step": 70}
{"loss": 0.00644121, "acc": 0.49969511, "grad_norm": 0.27148438, "learning_rate": 2.632e-05, "epoch": 40.0, "global_step": 75}
{"loss": 0.00537246, "acc": 0.49939022, "grad_norm": 0.09814453, "learning_rate": 2.105e-05, "epoch": 42.66666667, "global_step": 80}
{"loss": 0.00413303, "acc": 0.4375, "grad_norm": 0.07958984, "learning_rate": 1.579e-05, "epoch": 45.0, "global_step": 85}
{"loss": 0.00498675, "acc": 0.5625, "grad_norm": 0.09082031, "learning_rate": 1.053e-05, "epoch": 48.0, "global_step": 90}
{"loss": 0.00483434, "acc": 0.5625, "grad_norm": 0.16210938, "learning_rate": 5.26e-06, "epoch": 51.0, "global_step": 95}
{"loss": 0.00367432, "acc": 0.4375, "grad_norm": 0.05493164, "learning_rate": 0.0, "epoch": 53.33333333, "global_step": 100}
{"eval_loss": 0.69106913, "eval_acc": 0.76744186, "eval_runtime": 7.7567, "eval_samples_per_second": 0.129, "eval_steps_per_second": 0.129, "epoch": 53.33333333, "global_step": 100}
{"train_runtime": 584.8958, "train_samples_per_second": 2.736, "train_steps_per_second": 0.171, "total_flos": 74653983221760.0, "train_loss": 0.28366758, "epoch": 53.33333333, "global_step": 100}
{"memory": {"cuda:0": "1.32GiB"}, "gen_time": 0.0, "gen_len": 0, "train_time": {"train_runtime": 584.8958, "n_train_samples": 15, "train_samples_per_second": 0.02564559362539447}, "last_model_checkpoint": "C:\\Users\\45092\\Desktop\\cleanllm\\output\\qwen1half-0_5b-chat\\v72-20240621-140351\\checkpoint-100", "best_model_checkpoint": "C:\\Users\\45092\\Desktop\\cleanllm\\output\\qwen1half-0_5b-chat\\v72-20240621-140351\\checkpoint-50", "best_metric": 0.66162658, "global_step": 100, "log_history": [{"loss": 3.49956155, "acc": 0.4019517, "grad_norm": 6.4375, "learning_rate": 2e-05, "epoch": 1.0, "step": 1}, {"loss": 1.69518483, "acc": 0.20142452, "grad_norm": 4.1875, "learning_rate": 0.0001, "epoch": 3.0, "step": 5}, {"loss": 1.179321, "acc": 0.22218409, "grad_norm": 1.53125, "learning_rate": 9.473684210526316e-05, "epoch": 5.333333333333333, "step": 10}, {"loss": 0.8430027, "acc": 0.32917449, "grad_norm": 1.34375, "learning_rate": 8.947368421052632e-05, "epoch": 8.0, "step": 15}, {"loss": 0.57016377, "acc": 0.39561129, "grad_norm": 1.2578125, "learning_rate": 8.421052631578948e-05, "epoch": 10.666666666666666, "step": 20}, {"loss": 0.32824948, "acc": 0.36537356, "grad_norm": 0.369140625, "learning_rate": 7.894736842105263e-05, "epoch": 13.0, "step": 25}, {"loss": 0.27504699, "acc": 0.48988757, "grad_norm": 1.3984375, "learning_rate": 7.368421052631579e-05, "epoch": 16.0, "step": 30}, {"loss": 0.1609871, "acc": 0.51440158, "grad_norm": 1.109375, "learning_rate": 6.842105263157895e-05, "epoch": 19.0, "step": 35}, {"loss": 0.08093585, "acc": 0.41482348, "grad_norm": 0.546875, "learning_rate": 6.31578947368421e-05, "epoch": 21.333333333333332, "step": 40}, {"loss": 0.05608666, "acc": 0.4839025, "grad_norm": 0.59375, "learning_rate": 5.789473684210527e-05, "epoch": 24.0, "step": 45}, {"loss": 0.03458886, "acc": 0.49087057, "grad_norm": 0.6171875, "learning_rate": 5.2631578947368424e-05, "epoch": 26.666666666666668, "step": 50}, {"eval_loss": 0.6616265773773193, "eval_acc": 0.7906976744186046, "eval_runtime": 7.885, "eval_samples_per_second": 0.127, "eval_steps_per_second": 0.127, "epoch": 26.666666666666668, "step": 50}, {"loss": 0.02210911, "acc": 0.4319459, "grad_norm": 0.4453125, "learning_rate": 4.736842105263158e-05, "epoch": 29.0, "step": 55}, {"loss": 0.01778363, "acc": 0.55861731, "grad_norm": 0.3046875, "learning_rate": 4.210526315789474e-05, "epoch": 32.0, "step": 60}, {"loss": 0.01234441, "acc": 0.56028085, "grad_norm": 0.3125, "learning_rate": 3.6842105263157895e-05, "epoch": 35.0, "step": 65}, {"loss": 0.00722974, "acc": 0.4366137, "grad_norm": 0.2197265625, "learning_rate": 3.157894736842105e-05, "epoch": 37.333333333333336, "step": 70}, {"loss": 0.00644121, "acc": 0.49969511, "grad_norm": 0.271484375, "learning_rate": 2.6315789473684212e-05, "epoch": 40.0, "step": 75}, {"loss": 0.00537246, "acc": 0.49939022, "grad_norm": 0.09814453125, "learning_rate": 2.105263157894737e-05, "epoch": 42.666666666666664, "step": 80}, {"loss": 0.00413303, "acc": 0.4375, "grad_norm": 0.07958984375, "learning_rate": 1.5789473684210526e-05, "epoch": 45.0, "step": 85}, {"loss": 0.00498675, "acc": 0.5625, "grad_norm": 0.0908203125, "learning_rate": 1.0526315789473684e-05, "epoch": 48.0, "step": 90}, {"loss": 0.00483434, "acc": 0.5625, "grad_norm": 0.162109375, "learning_rate": 5.263157894736842e-06, "epoch": 51.0, "step": 95}, {"loss": 0.00367432, "acc": 0.4375, "grad_norm": 0.054931640625, "learning_rate": 0.0, "epoch": 53.333333333333336, "step": 100}, {"eval_loss": 0.6910691261291504, "eval_acc": 0.7674418604651163, "eval_runtime": 7.7567, "eval_samples_per_second": 0.129, "eval_steps_per_second": 0.129, "epoch": 53.333333333333336, "step": 100}, {"train_runtime": 584.8958, "train_samples_per_second": 2.736, "train_steps_per_second": 0.171, "total_flos": 74653983221760.0, "train_loss": 0.283667580652982, "epoch": 53.333333333333336, "step": 100}], "model_info": "PeftModelForCausalLM: 467.7724M Params (3.7847M Trainable [0.8091%]), 100.6641M Buffers.", "dataset_info": {"train_dataset": "49.800000\u00b115.954937, min=32.000000, max=70.000000, size=15", "val_dataset": "66.000000\u00b10.000000, min=66.000000, max=66.000000, size=1"}}
